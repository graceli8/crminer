crminer
=======

```{r echo=FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  comment = "#>",
  cache.path = "inst/cache/"
)
```

[![Build Status](https://travis-ci.org/ropensci/crminer.svg?branch=master)](https://travis-ci.org/ropensci/crminer)
[![codecov.io](https://codecov.io/github/ropensci/crminer/coverage.svg?branch=master)](https://codecov.io/github/ropensci/crminer?branch=master)

Publishers can optionally provide links in the metadata they provide to Crossref for full text of the work, but that data is often missing. Find out more about it at <http://tdmsupport.crossref.org/>

## Authentication

coming soon ...

## Install

Development version

```{r eval=FALSE}
devtools::install_github("ropensci/crminer")
```

```{r}
library("crminer")
library("rcrossref")
```

## Search

Get some DOIs for articles that provide full text, and that have
`CC-BY 4.0` licenses (i.e., more likely to actually be open), and from
PeerJ

```{r cache=TRUE}
out <-
  cr_members(4443, works = TRUE, filter = list(
    has_full_text = TRUE,
    license_url = "http://creativecommons.org/licenses/by/4.0/")
  )
(dois <- out$data$DOI)
```

## Get full text links

Then get URLs to full text content

```{r}
links <- lapply(dois, crm_links, type = "xml")
(links <- Filter(Negate(is.null), links))[1:5]
```

## Get full text

### XML

Then use those URLs to get full text

```{r eval=FALSE}
crm_text(url = links[[1]])
#> {xml_document}
#> <article article-type="research-article" dtd-version="1.0" xmlns:xlink="http://www.w3.org/1999/xlink" ...
#> [1] <front>\n  <journal-meta>\n    <journal-id journal-id-type="publisher-id">peerj-cs</journal-id>\n ...
#> [2] <body>\n  <sec sec-type="intro">\n    <title>Introduction</title>\n    <p>The question of natural ...
#> [3] <back>\n  <sec sec-type="additional-information">\n    <title>Additional Information and Declarat ...
```

### PDF

Sometimes you can only get a pdf, in that case we will extract text from 
the pdf for you on use of `crm_text()`

```{r}
links <- lapply(dois, crm_links, type = "pdf")
(links <- Filter(Negate(is.null), links))[1:5]
```

The get pdf and text is extracted

```{r}
(res <- crm_text(url = links[[1]], type = "pdf"))
```

```{r}
cat(substring(res$text[[1]], 1, 300))
```

## Extract text from pdf

If you already have a path to the pdf, use `crm_extract()`

```{r}
path <- system.file("examples", "MairChamberlain2014RJournal.pdf", package = "crminer")
(res <- crm_extract(path))
res$info
cat(substring(res$text[[1]], 1, 300))
```


## Meta

* Please [report any issues or bugs](https://github.com/ropensci/crminer/issues).
* License: MIT
* Get citation information for `crminer` in R doing `citation(package = 'crminer')`
* Please note that this project is released with a [Contributor Code of Conduct](CONDUCT.md). By participating in this project you agree to abide by its terms.

[![rofooter](https://ropensci.org/public_images/github_footer.png)](https://ropensci.org)
